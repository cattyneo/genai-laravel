# GenAI Models Configuration
# This file contains all model definitions for different providers
# Based on config/genai.php models section

# ===== OpenAI =====
openai:
  gpt-4.1:
    provider: openai
    model: gpt-4.1
    type: text
    features:
      - vision
      - function_calling
      - structured_output
    pricing:
      input: 1.10  # $/1M tokens
      output: 4.40
      cached_input: 0.275  # 75% discount
    limits:
      max_tokens: 16384
      context_window: 1000000  # 1M tokens
      requests_per_minute: 10000

  gpt-4.1-mini:
    provider: openai
    model: gpt-4.1-mini
    type: text
    features:
      - vision
      - function_calling
      - structured_output
    pricing:
      input: 0.40
      output: 1.60
      cached_input: 0.10
    limits:
      max_tokens: 16384
      context_window: 1000000
      requests_per_minute: 30000

  gpt-4.1-nano:
    provider: openai
    model: gpt-4.1-nano
    type: text
    features:
      - vision
      - function_calling
      - structured_output
    pricing:
      input: 0.10
      output: 0.40
      cached_input: 0.025
    limits:
      max_tokens: 16384
      context_window: 1000000
      requests_per_minute: 50000

  o3:
    provider: openai
    model: o3
    type: text
    features:
      - reasoning
    pricing:
      input: 10.00
      output: 40.00
      reasoning: 40.00
    limits:
      max_tokens: 100000
      context_window: 200000
      requests_per_minute: 100

  o4-mini:
    provider: openai
    model: o4-mini
    type: text
    features:
      - reasoning
    pricing:
      input: 1.10
      output: 4.40
      reasoning: 4.40
    limits:
      max_tokens: 65536
      context_window: 128000
      requests_per_minute: 1000

  gpt-4.5-preview:
    provider: openai
    model: gpt-4.5-preview
    type: text
    features:
      - vision
      - function_calling
      - structured_output
    pricing:
      input: 0.10
      output: 0.40
      cached_input: 0.025
    limits:
      max_tokens: 16384
      context_window: 128000
      requests_per_minute: 10000

  gpt-image-1:
    provider: openai
    model: gpt-image-1
    type: image
    features:
      - image_generation
    pricing:
      standard:
        "1024x1024": 0.040
        "1024x1792": 0.080
        "1792x1024": 0.080
      hd:
        "1024x1024": 0.080
        "1024x1792": 0.120
        "1792x1024": 0.120
    limits:
      images_per_minute: 5

# ===== Gemini =====
gemini:
  gemini-2.5-flash:
    provider: gemini
    model: gemini-2.5-flash-preview-05-20
    type: text
    features:
      - vision
      - function_calling
      - structured_output
      - grounding
      - reasoning
    pricing:
      input: 0.10
      output: 0.40
    limits:
      max_tokens: 8192
      context_window: 1000000
      requests_per_minute: 1000

  gemini-2.5-pro:
    provider: gemini
    model: gemini-2.5-pro-preview-05-06
    type: text
    features:
      - vision
      - function_calling
      - structured_output
      - grounding
      - reasoning
    pricing:
      input: 1.25  # 200K以下
      output: 10.00
    limits:
      max_tokens: 8192
      context_window: 1000000  # 2M coming soon
      requests_per_minute: 360

# ===== Claude =====
claude:
  claude-sonnet-4:
    provider: claude
    model: claude-sonnet-4-20250514
    type: text
    features:
      - vision
      - function_calling
      - structured_output
      - reasoning
    pricing:
      input: 3.00
      output: 15.00
      cached_input: 0.30
    limits:
      max_tokens: 64000
      context_window: 200000

  claude-opus-4:
    provider: claude
    model: claude-opus-4-20250514
    type: text
    features:
      - vision
      - function_calling
      - structured_output
      - reasoning
    pricing:
      input: 15.00
      output: 75.00
      cached_input: 1.50
    limits:
      max_tokens: 32000
      context_window: 200000

# ===== Grok =====
grok:
  grok-3:
    provider: grok
    model: grok-3
    type: text
    features:
      - function_calling
      - reasoning
    pricing:
      input: 5.00
      output: 15.00
    limits:
      max_tokens: 131072
      context_window: 1000000  # 1M announced but API limited to 131k

  grok-3-fast:
    provider: grok
    model: grok-3-fast
    type: text
    features:
      - function_calling
    pricing:
      input: 1.00
      output: 3.00
    limits:
      max_tokens: 131072
      context_window: 131072

  grok-3-mini:
    provider: grok
    model: grok-3-mini
    type: text
    features:
      - function_calling
      - reasoning
    pricing:
      input: 0.50
      output: 1.50
    limits:
      max_tokens: 131072
      context_window: 131072

  grok-3-mini-fast:
    provider: grok
    model: grok-3-mini-fast
    type: text
    features:
      - function_calling
    pricing:
      input: 0.10
      output: 0.30
    limits:
      max_tokens: 131072
      context_window: 131072